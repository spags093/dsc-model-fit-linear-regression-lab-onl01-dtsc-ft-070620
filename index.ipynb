{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit in Linear Regression - Lab\n",
    "\n",
    "## Introduction\n",
    "In this lab, you'll learn how to evaluate your model results and you'll learn how to select the appropriate features using stepwise selection.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Use stepwise selection methods to determine the most important features for a model\n",
    "* Use recursive feature elimination to determine the most important features for a model\n",
    "\n",
    "## The Ames Housing Data once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::gensim==3.7.3=py36h0a44026_0\n",
      "  - defaults/osx-64::h5py==2.9.0=py36h3134771_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - conda-forge/osx-64::jupyter_contrib_nbextensions==0.5.1=py36_0\n",
      "  - conda-forge/osx-64::jupyter_highlight_selected_word==0.2.0=py36_1000\n",
      "  - conda-forge/osx-64::jupyter_latex_envs==1.4.4=py36_1000\n",
      "  - conda-forge/osx-64::jupyter_nbextensions_configurator==0.4.1=py36_0\n",
      "  - defaults/osx-64::mkl_fft==1.0.14=py36h5e564d8_0\n",
      "  - defaults/osx-64::mkl_random==1.1.0=py36ha771720_0\n",
      "  - defaults/osx-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/osx-64::nb_conda_kernels==2.2.1=py36_0\n",
      "  - defaults/noarch::nbconvert==5.5.0=py_0\n",
      "  - defaults/osx-64::notebook==5.7.8=py36_0\n",
      "  - defaults/osx-64::numpy==1.16.5=py36hacdab7b_0\n",
      "  - defaults/osx-64::patsy==0.5.1=py36_0\n",
      "  - defaults/osx-64::py-xgboost==0.90=py36h0a44026_1\n",
      "  - defaults/noarch::pyspark==2.4.4=py_0\n",
      "  - defaults/osx-64::scikit-learn==0.21.2=py36h27c97d8_0\n",
      "  - defaults/osx-64::scipy==1.3.1=py36h1410ff5_0\n",
      "  - defaults/osx-64::statsmodels==0.10.1=py36h1d22016_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/spags/opt/anaconda3/envs/learn-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - statsmodels\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    numpy-1.19.1               |   py36h3b9f5b6_0          21 KB\n",
      "    numpy-base-1.19.1          |   py36hcfb5961_0         4.0 MB\n",
      "    pandas-0.22.0              |   py36h0a44026_0         7.7 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bleach             pkgs/main/noarch::bleach-3.1.5-py_0\n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.19.1-py36hcfb5961_0\n",
      "  pandas             pkgs/main/osx-64::pandas-0.22.0-py36h0a44026_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  numpy                               1.16.5-py36hacdab7b_0 --> 1.19.1-py36h3b9f5b6_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "numpy-1.19.1         | 21 KB     | ##################################### | 100% \n",
      "pandas-0.22.0        | 7.7 MB    | ##################################### | 100% \n",
      "numpy-base-1.19.1    | 4.0 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda upgrade statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for stepwise selection is copied below. Use this provided function on your preprocessed Ames Housing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spags/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:27: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  GrLivArea_log                  with p-value 1.59847e-243\n",
      "Add  KitchenQual_TA                 with p-value 1.56401e-67\n",
      "Add  1stFlrSF_log                   with p-value 7.00069e-48\n",
      "Add  KitchenQual_Fa                 with p-value 1.70471e-37\n",
      "Add  Neighborhood_OldTown           with p-value 3.20105e-23\n",
      "Add  KitchenQual_Gd                 with p-value 4.12635e-21\n",
      "Add  Neighborhood_Edwards           with p-value 9.05184e-17\n",
      "Add  Neighborhood_IDOTRR            with p-value 1.10068e-18\n",
      "Add  LotArea_log                    with p-value 1.71728e-13\n",
      "Add  Neighborhood_NridgHt           with p-value 7.05633e-12\n",
      "Add  BldgType_Duplex                with p-value 4.30647e-11\n",
      "Add  Neighborhood_NAmes             with p-value 2.25803e-09\n",
      "Add  Neighborhood_SWISU             with p-value 5.40743e-09\n",
      "Add  Neighborhood_BrkSide           with p-value 8.79638e-10\n",
      "Add  Neighborhood_Sawyer            with p-value 6.92011e-09\n",
      "Add  Neighborhood_NoRidge           with p-value 5.87105e-08\n",
      "Add  Neighborhood_Somerst           with p-value 3.00722e-08\n",
      "Add  Neighborhood_StoneBr           with p-value 6.58621e-10\n",
      "Add  Neighborhood_MeadowV           with p-value 2.26069e-05\n",
      "Add  SaleType_New                   with p-value 0.000485363\n",
      "Add  SaleType_WD                    with p-value 0.00253157\n",
      "Add  Neighborhood_BrDale            with p-value 0.00374541\n",
      "Add  MSZoning_RM                    with p-value 8.29694e-05\n",
      "Add  MSZoning_RL                    with p-value 0.00170469\n",
      "Add  MSZoning_FV                    with p-value 0.00114668\n",
      "Add  MSZoning_RH                    with p-value 3.95797e-05\n",
      "Add  Neighborhood_NWAmes            with p-value 0.00346099\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6c41b994aa39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice_log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepwise_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resulting features:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-49c095109920>\u001b[0m in \u001b[0;36mstepwise_selection\u001b[0;34m(X, y, initial_list, threshold_in, threshold_out, verbose)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mchanged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mworst_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mincluded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Drop {:30} with p-value {:.6}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworst_pval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "# y = preprocessed['SalePrice_log']\n",
    "\n",
    "# result = stepwise_selection(X, y, verbose = True)\n",
    "# result\n",
    "\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']\n",
    "\n",
    "result = stepwise_selection(X, y, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final model again in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5d5109d09581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_with_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_with_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "x_final = X[result]\n",
    "x_with_intercept = sm.add_constant(x_final)\n",
    "model = sm.ols(y, x_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature ranking to select the 5 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 5)\n",
    "selector = selector.fit(X, y.values.ravel())\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model again using the 5 selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "selected_columns = X.columns[selector.support_]\n",
    "linreg.fit(X[selected_columns], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict $\\hat y$ using your model. You can use `.predict()` in scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10023007 0.10023007 0.10023007 ... 0.10023007 0.10023007 0.10023007]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "y_predictions = linreg.predict(X[selected_columns])\n",
    "print(y_predictions)\n",
    "len(y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the formulas of R-squared and adjusted R-squared below, and your Python/numpy knowledge, compute them and contrast them with the R-squared and adjusted R-squared in your statsmodels output using stepwise selection. Which of the two models would you prefer?\n",
    "\n",
    "$SS_{residual} = \\sum (y - \\hat{y})^2 $\n",
    "\n",
    "$SS_{total} = \\sum (y - \\bar{y})^2 $\n",
    "\n",
    "$R^2 = 1- \\dfrac{SS_{residual}}{SS_{total}}$\n",
    "\n",
    "$R^2_{adj}= 1-(1-R^2)\\dfrac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared is 0.7605658182288547\n",
      "r_squared_adj is 0.7597424544676059\n"
     ]
    }
   ],
   "source": [
    "# Your code here = Messed up somewhere\n",
    "\n",
    "ss_residual = np.sum((y_predictions) **2)\n",
    "ss_total = np.sum(((y - np.mean(y))**2))\n",
    "r_squared = 1 -(ss_residual/ss_total)\n",
    "r_squared_adj = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)\n",
    "\n",
    "print(\"r_squared is {}\".format(r_squared))\n",
    "print(\"r_squared_adj is {}\".format(r_squared_adj))\n",
    "\n",
    "# SS_Residual = np.sum((y_predictions)**2)\n",
    "# SS_Total = np.sum((y-np.mean(y))**2)\n",
    "# r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "# adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)\n",
    "\n",
    "# r_squared\n",
    "\n",
    "\n",
    "# r_squared is 0.239434  \n",
    "# adjusted_r_squared is 0.236818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "- Perform variable selection using forward selection, using this resource: https://planspace.org/20150423-forward_selection_with_statsmodels/. Note that this time features are added based on the adjusted R-squared!\n",
    "- Tweak the code in the `stepwise_selection()` function written above to just perform forward selection based on the p-value \n",
    "\n",
    "## Summary\n",
    "Great! You practiced your feature selection skills by applying stepwise selection and recursive feature elimination to the Ames Housing dataset! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
